{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6076457,"sourceType":"datasetVersion","datasetId":3296934}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **MONKEYPOX DETECTION USING DEEP LEARNING MODELS AND EXPLAINABLE AI WITH FEDERATED LEARNING**","metadata":{"id":"yKEndLScNmXG"}},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"TMDHyDG6Nu_5"}},{"cell_type":"markdown","source":"RATIONELE FOR PROJECT\n\nMpox, formerly known as monkeypox, is a rare but potentially serious viral disease caused by the monkeypox virus, a species of the genus Orthopoxvirus (World Health Organization, 2024). The disease has two distinct clades: clade I (with subclades Ia and Ib) and clade II (with subclades IIa and IIb), with clade II being the most recent mpox that has caused a global outbreak in 2024 (CDC, 2024). The focus of this project is to examine how Machine Learning models can be utilized to accurately diagnose specific disease through classification and detection techniques while considering racial bias. The ongoing global outbreak of clade II has caused more than 100 00 cases in 122 countries, including 115 countries where Mpox was not reported previously (CDC, 2024).\n\nThe fatality rate of Mpox can reach up to 11% depending on the strain and the health condition of the affected individual, with the Clade I having a mortality rate of around 3.6% (Mpox Virus: Clade I and Clade II, n.d). There is no specific treatment for Mpox, antiviral medications like tecovirimat (TPOXX) can help mitigate symptoms, but these treatments are not accessible in underprivileged areas (CDC, 2024). With the ongoing violence in the Democratic Republic of Congo, efforts to control Mpox have been severely hindered by ongoing violence, which results in higher transmission rates and delayed responses.\n\nThe traditional diagnosis method is PCR testing, and Serological testing, where PCR is the primary method that uses samples from skin lesions and is the most preferred because of its high sensitivity and specificity, while Serological tests detect antibodies, but this test is less reliable due to its cross-reactivity with other orthopoxviruses (Khehra, Padda and Swift, 2023). Both these methods have their limitations, and these include the need for specialized equipment and trained personnel and the potential for false negatives due to viral mutations. Enhancing diagnostic accuracy and accessibility, especially in resource-limited environments, requires the development of a reliable computer-based framework for the detection of Mpox disease. The goal is to provide an accessible, reliable tool that aids healthcare professionals in conflict zones and underprivileged areas","metadata":{"id":"59MMEgKqNpgO"}},{"cell_type":"markdown","source":"AIMS AND OBJECTIVES\n\nAIM\n\nTo implement a robust, privacy-preserving, racially fair, and explainable Deep Learning framework integrated with Federated Learning for early and accurate Mpox detection.\n\nOBJECTIVES\n\n1.    Implement a Deep Learning model using Transfer Learning and Federated Learning on diverse skin lesion datasets to accurately classify Mpox.\n\n2.    Assess and mitigate the impact of skin tone variations on model performance to ensure racial fairness in diagnosis.\n\n3.    Integrate and evaluate Explainable AI techniques such as Grad-CAM and LIME to improve transparency and trustworthiness of the model‚Äôs predictions.\n\n4.    Benchmark the proposed framework against traditional diagnostic methods and recent Deep Learning approaches using robust cross-validation techniques.\n\n","metadata":{"id":"pk2GPBJwNxym"}},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"5COQRK_pN-mb"}},{"cell_type":"markdown","source":"## 1. IMPORT IMPORTANT LIBRARIES","metadata":{"id":"MwkiG-0IOAmT"}},{"cell_type":"code","source":"pip install imgaug opencv-python","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRH5tlk-NaYv","outputId":"acac85b9-7f6c-44c7-a713-ff9c4acbbf88","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:33.180343Z","iopub.execute_input":"2025-08-24T11:45:33.181184Z","iopub.status.idle":"2025-08-24T11:45:36.437087Z","shell.execute_reply.started":"2025-08-24T11:45:33.181158Z","shell.execute_reply":"2025-08-24T11:45:36.435925Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: imgaug in /usr/local/lib/python3.11/dist-packages (0.4.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.17.0)\nRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug) (11.2.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug) (3.7.2)\nRequirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from imgaug) (0.25.2)\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.37.0)\nRequirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.1.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (2.4.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (3.5)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (2025.6.11)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (25.0)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (2.9.0.post0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15->imgaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15->imgaug) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.15->imgaug) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.15->imgaug) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.15->imgaug) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install \"numpy<2\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:36.439186Z","iopub.execute_input":"2025-08-24T11:45:36.439870Z","iopub.status.idle":"2025-08-24T11:45:39.501080Z","shell.execute_reply.started":"2025-08-24T11:45:36.439842Z","shell.execute_reply":"2025-08-24T11:45:39.500349Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:39.502255Z","iopub.execute_input":"2025-08-24T11:45:39.502468Z","iopub.status.idle":"2025-08-24T11:45:42.693759Z","shell.execute_reply.started":"2025-08-24T11:45:39.502444Z","shell.execute_reply":"2025-08-24T11:45:42.693012Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n#import tensorflow as tf\nimport seaborn as sns\nfrom PIL import Image\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nimport os\nimport shutil\nimport zipfile\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import resample\n#import imgaug.augmenters as iaa\nfrom skimage import io\n#from imgaug.augmentables.segmaps import SegmentationMapsOnImage\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adamax\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport os\nimport numpy as np\nimport pandas as pd\nfrom skimage import io","metadata":{"id":"DuDWBfyVOH-p","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:42.694629Z","iopub.execute_input":"2025-08-24T11:45:42.694842Z","iopub.status.idle":"2025-08-24T11:45:46.602543Z","shell.execute_reply.started":"2025-08-24T11:45:42.694818Z","shell.execute_reply":"2025-08-24T11:45:46.601979Z"}},"outputs":[{"name":"stderr","text":"2025-08-24 11:45:43.911326: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756035943.933795      99 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756035943.940610      99 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\nfrom tensorflow.keras.applications import ResNet152V2\nfrom keras.applications import ResNet152V2\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adamax\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import load_model\nfrom skimage import io\nimport imgaug.augmenters as iaa\nfrom imgaug.augmentables.segmaps import SegmentationMapsOnImage\nimport cv2","metadata":{"id":"wkBZbtI5wM6G","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.604193Z","iopub.execute_input":"2025-08-24T11:45:46.604673Z","iopub.status.idle":"2025-08-24T11:45:46.662402Z","shell.execute_reply.started":"2025-08-24T11:45:46.604652Z","shell.execute_reply":"2025-08-24T11:45:46.661848Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 2. IMPORT DATASETS AND CREATION OF DATASETS","metadata":{"id":"QNisT_cNOsCg"}},{"cell_type":"code","source":"# Replace with your image path\nimage_path = '/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Keywords.jpg'\n\n# Open and display the image\nimage = Image.open(image_path)\nplt.imshow(image)\nplt.axis('off')  # Hide axis\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"9Q_RLGe3w4dG","outputId":"6f901a64-e265-4e83-a2bf-8eeec202f5cc","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:46:16.086095Z","iopub.execute_input":"2025-08-24T11:46:16.086368Z","iopub.status.idle":"2025-08-24T11:46:16.102742Z","shell.execute_reply.started":"2025-08-24T11:46:16.086346Z","shell.execute_reply":"2025-08-24T11:46:16.101779Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_99/1145007413.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Open and display the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Hide axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Keywords.jpg'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Keywords.jpg'","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"log=pd.read_excel('/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/datalog.xlsx')\nprint(log)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_d2EksAROMDl","outputId":"40057c53-9a2a-49d2-b38a-e2f4314ee45a","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:46:12.406057Z","iopub.execute_input":"2025-08-24T11:46:12.406346Z","iopub.status.idle":"2025-08-24T11:46:12.502946Z","shell.execute_reply.started":"2025-08-24T11:46:12.406325Z","shell.execute_reply":"2025-08-24T11:46:12.502021Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_99/1926543678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/datalog.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/datalog.xlsx'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/datalog.xlsx'","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"# Define paths (these are already directories, not zip files)\naug_folder = \"/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Augmented Images\"\norig_folder = \"/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Original Images\"\n\n# Example: List some image files from the augmented folder\nfor root, dirs, files in os.walk(aug_folder):\n    for file in files[:5]:  # Just print first 5 files\n        print(os.path.join(root, file))\n    break  # Remove this if you want to walk through all subdirectories","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.970554Z","iopub.status.idle":"2025-08-24T11:45:46.970909Z","shell.execute_reply.started":"2025-08-24T11:45:46.970733Z","shell.execute_reply":"2025-08-24T11:45:46.970748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Paths to ZIP files\naug_zip = \"/content/drive/MyDrive/PROJECT DATASETS/Augmented Images.zip\"\norig_zip = \"/content/drive/MyDrive/PROJECT DATASETS/Original Images.zip\"\n\nUnzip both folders\nwith zipfile.ZipFile(aug_zip, 'r') as zip_ref:\n    zip_ref.extractall(\"Augmented_Images\")\n\nwith zipfile.ZipFile(orig_zip, 'r') as zip_ref:\n    zip_ref.extractall(\"Original_Images\")","metadata":{"id":"EjO2DekE4oBk"}},{"cell_type":"markdown","source":"### Augmented Images","metadata":{"id":"7Uov6nagbqTg"}},{"cell_type":"code","source":"# Classes (folder names)\n#diagnosis_classes = ['Monkeypox', 'Chickenpox', 'Measles', 'Cowpox', 'Healthy', 'HFMD']","metadata":{"id":"8YCHlZGm2wgt","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.972013Z","iopub.status.idle":"2025-08-24T11:45:46.972314Z","shell.execute_reply.started":"2025-08-24T11:45:46.972154Z","shell.execute_reply":"2025-08-24T11:45:46.972170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Adjust this to your actual root path\nbase_dir = \"/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Augmented Images/Augmented Images/FOLDS_AUG\"\n\n# Define folds and splits\nfolds = ['fold1_AUG', 'fold2_AUG', 'fold3_AUG', 'fold4_AUG', 'fold5_AUG']\nsplits = ['Train']\n\n# Initialize records list\nrecords = []\n\nfor fold in folds:\n    for split in splits:\n        split_path = os.path.join(base_dir, fold, split)\n        if not os.path.exists(split_path):\n            continue\n\n        # Dynamically detect class folders under each split\n        for diagnosis in os.listdir(split_path):\n            class_path = os.path.join(split_path, diagnosis)\n            if not os.path.isdir(class_path):\n                continue  # Skip files\n\n            # Iterate over image files\n            for img_file in os.listdir(class_path):\n                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n                    image_id = os.path.splitext(img_file)[0]\n                    lesion_id = \"_\".join(image_id.split('_')[:3])\n                    image_path = os.path.join(class_path, img_file)\n\n                    records.append({\n                        \"lesion_Id\": lesion_id,\n                        \"image_Id\": image_id,\n                        \"diagnosis\": diagnosis,\n                        \"image_Path\": image_path,\n                        \"fold\": fold,\n                        \"split\": split\n                    })\n\n# Convert to DataFrame\ndf = pd.DataFrame(records)\n\n# Save to CSV\ndf.to_csv(\"all_folds_dataset.csv\", index=False)\nprint(f\"‚úÖ Saved dataset with {len(df)} entries to 'all_folds_dataset.csv'\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QmmXsI0e1yv","outputId":"75f0d7d2-034f-42ef-b25b-140d766b8fe8","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.973300Z","iopub.status.idle":"2025-08-24T11:45:46.973595Z","shell.execute_reply.started":"2025-08-24T11:45:46.973454Z","shell.execute_reply":"2025-08-24T11:45:46.973467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"td0b5qP0fndJ","outputId":"61da573a-8b79-4eb6-b66f-5bb42bda1fa6","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.974829Z","iopub.status.idle":"2025-08-24T11:45:46.975100Z","shell.execute_reply.started":"2025-08-24T11:45:46.974949Z","shell.execute_reply":"2025-08-24T11:45:46.974959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Original Datasets","metadata":{"id":"dGe2yIb9cSK4"}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Adjust this to your actual root path\nbase_dir = \"/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Original Images/Original Images/FOLDS\"\n\n# Define folds and splits\nfolds = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\nsplits = ['Train', 'Test', 'Valid']\n\n# Initialize records list\nrecords = []\n\nfor fold in folds:\n    for split in splits:\n        split_path = os.path.join(base_dir, fold, split)\n        if not os.path.exists(split_path):\n            continue\n\n        # Dynamically detect class folders under each split\n        for diagnosis in os.listdir(split_path):\n            class_path = os.path.join(split_path, diagnosis)\n            if not os.path.isdir(class_path):\n                continue  # Skip files\n\n            # Iterate over image files\n            for img_file in os.listdir(class_path):\n                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n                    image_id = os.path.splitext(img_file)[0]\n                    lesion_id = \"_\".join(image_id.split('_')[:3])\n                    image_path = os.path.join(class_path, img_file)\n\n                    records.append({\n                        \"lesion_Id\": lesion_id,\n                        \"image_Id\": image_id,\n                        \"diagnosis\": diagnosis,\n                        \"image_Path\": image_path,\n                        \"fold\": fold,\n                        \"split\": split\n                    })\n\n# Convert to DataFrame\ndf_all = pd.DataFrame(records)\n\n# Save to CSV\ndf_all.to_csv(\"all_folds_dataset.csv\", index=False)\nprint(f\"‚úÖ Saved dataset with {len(df_all)} entries to 'all_folds_dataset.csv'\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArftGN_ydXDY","outputId":"04a1e16b-cea8-484e-8ad9-5eae9d22c5c3","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.976293Z","iopub.status.idle":"2025-08-24T11:45:46.976518Z","shell.execute_reply.started":"2025-08-24T11:45:46.976412Z","shell.execute_reply":"2025-08-24T11:45:46.976423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"pbTIwTytdG3I","outputId":"9bf20413-fde1-4849-89d7-28cd7e1c740e","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.977133Z","iopub.status.idle":"2025-08-24T11:45:46.977419Z","shell.execute_reply.started":"2025-08-24T11:45:46.977269Z","shell.execute_reply":"2025-08-24T11:45:46.977282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all['diagnosis'].nunique()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q184jsx_dKFV","outputId":"ebc8ab59-38fe-47d8-e711-f8b1e9514ace","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.978440Z","iopub.status.idle":"2025-08-24T11:45:46.978774Z","shell.execute_reply.started":"2025-08-24T11:45:46.978626Z","shell.execute_reply":"2025-08-24T11:45:46.978642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Concatenate all dataframes\ncombined_df = pd.concat([df,df_all], ignore_index=True)\n\n# Optional: Shuffle the combined dataset\ncombined_df = combined_df.sample(frac=1).reset_index(drop=True)\n\n# Save to CSV\ncombined_df.to_csv(\"combined_dataset.csv\", index=False)\n\nprint(\"‚úÖ Concatenated dataset saved as 'combined_dataset.csv'\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZtM6_7hd6ib","outputId":"2ad56932-1870-4bef-b6d8-d412d326e14d","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.979310Z","iopub.status.idle":"2025-08-24T11:45:46.979587Z","shell.execute_reply.started":"2025-08-24T11:45:46.979459Z","shell.execute_reply":"2025-08-24T11:45:46.979469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"8V0KFmx1ejL4","outputId":"27e30133-77d5-49fd-8961-7254d3d3e9ec","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.980856Z","iopub.status.idle":"2025-08-24T11:45:46.981099Z","shell.execute_reply.started":"2025-08-24T11:45:46.980975Z","shell.execute_reply":"2025-08-24T11:45:46.980987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv(\"combined_dataset.csv\")","metadata":{"id":"Zhl8HsJijHBg","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.981916Z","iopub.status.idle":"2025-08-24T11:45:46.982229Z","shell.execute_reply.started":"2025-08-24T11:45:46.982068Z","shell.execute_reply":"2025-08-24T11:45:46.982081Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.1 EXPLORATORY DATA ANALYSIS","metadata":{"id":"pdVrxJVyetRZ"}},{"cell_type":"code","source":"print(\"üìä Basic Info:\")\nprint(df.info())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80a5G1QQemV9","outputId":"8de32878-fad4-407d-99a0-44afe06417f1","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.983786Z","iopub.status.idle":"2025-08-24T11:45:46.984081Z","shell.execute_reply.started":"2025-08-24T11:45:46.983926Z","shell.execute_reply":"2025-08-24T11:45:46.983943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This dataset is a DataFrame containing 40,819 entries and 6 columns, all of which are of type object. Each row represents a skin image sample with the following details:\n\n\n\n1.   Lesion_Id: Unique identifier for each lesion.\n2.   Image_Id: Unique identifier for each image.\n3. Diagnosis: The skin disease label (e.g., Mpox, Chickenpox).\n4. Image_Path: The file path to the image.\n5. Fold: Indicates the fold assignment (e.g., for cross-validation).\n6. Split: Indicates the data split (e.g., Train, Test, Validation).\n\nThere are no missing values in the dataset.","metadata":{"id":"p101MP8Ig5_X"}},{"cell_type":"code","source":"print(\"\\nüîç First few rows:\")\nprint(df.head())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jLf7fvkjSDM","outputId":"f1a886fb-55b1-41cb-bdff-9ff9a2115f35","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.985124Z","iopub.status.idle":"2025-08-24T11:45:46.985417Z","shell.execute_reply.started":"2025-08-24T11:45:46.985227Z","shell.execute_reply":"2025-08-24T11:45:46.985236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_counts = df.nunique()\n\nprint(\"\\nUnique entries in each column:\")\nprint(unique_counts)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kq1rlPvXg0R7","outputId":"224bbc32-ebb6-4f97-ac32-437426844e89","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.986795Z","iopub.status.idle":"2025-08-24T11:45:46.987095Z","shell.execute_reply.started":"2025-08-24T11:45:46.986925Z","shell.execute_reply":"2025-08-24T11:45:46.986936Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here‚Äôs a summary of the unique entries in each column of the dataset:\n\n*   Lesion_Id (755 unique): Many images belong to the same lesion, indicating multiple views per lesion.\n*   Image_Id (11,325 unique): Multiple image records may share the same image ID, possibly due to data augmentation or replication.\n\n*   Diagnosis (6 unique): There are six distinct skin disease classes (e.g., Mpox, Chickenpox, Measles, etc.).\n*   Image_Path (40,819 unique): Each entry refers to a unique image file path.\n\n*   Fold (10 unique): The dataset is divided into 10 folds, likely for cross-validation purposes.\n*   Split (3 unique): Images are categorized into Train, Validation, and Test sets.\n\n\n\n\n\n\n\nThis structure supports tasks like classification, lesion-level grouping, and model evaluation using cross-validation.","metadata":{"id":"kEviM49uhc1G"}},{"cell_type":"code","source":"# Replace with your image path\nimage_path = '/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Keywords.jpg'\n\n# Open and display the image\nimage = Image.open(image_path)\nplt.imshow(image)\nplt.axis('off')  # Hide axis\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"9Z9qF5WVhTVL","outputId":"a9e4e54a-48e8-48f7-ed95-205e8f45bf7c","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.987986Z","iopub.status.idle":"2025-08-24T11:45:46.988270Z","shell.execute_reply.started":"2025-08-24T11:45:46.988109Z","shell.execute_reply":"2025-08-24T11:45:46.988123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe(include='all')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"vpevVG1mjeFV","outputId":"e93490cf-3116-4a04-c547-a10c4dd5328a","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.989283Z","iopub.status.idle":"2025-08-24T11:45:46.989559Z","shell.execute_reply.started":"2025-08-24T11:45:46.989405Z","shell.execute_reply":"2025-08-24T11:45:46.989420Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here is a brief summary of the dataset based on the provided statistics:\n\n* Total Records: 40,819 images\n\n* Lesion_Id: 755 unique lesions, with the most frequent lesion (MKP_78_05) appearing 75 times, suggesting multiple images per lesion.\n\n* Image_Id: 11,325 unique images, with the most common (HEALTHY_104_01) appearing 5 times, indicating some images may be reused or augmented.\n\n* Diagnosis: 6 skin disease categories, with Monkeypox being the most common diagnosis (15,490 images).\n\n* Image_Path: All 40,819 entries have unique paths, confirming each path refers to a distinct image.\n\n* Fold: 10 unique folds (e.g., fold5_AUG) for cross-validation, with fold5_AUG being the most populated (7,532 images).\n\n* Split: 3 data splits ‚Äî Train, Validation, Test ‚Äî with the Train split containing the majority (39,690 images).\n\nThis dataset is structured for lesion-level classification with support for robust training and evaluation through folds and splits.","metadata":{"id":"ie_0kCAXjsE0"}},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBMp9DFOjjct","outputId":"a7e2653f-7088-421f-a045-b44f8c543f74","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.990793Z","iopub.status.idle":"2025-08-24T11:45:46.991020Z","shell.execute_reply.started":"2025-08-24T11:45:46.990911Z","shell.execute_reply":"2025-08-24T11:45:46.990921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This output shows that there are no missing values in the dataset ‚Äî all 40,819 rows have complete entries across all six columns.\n\n‚úÖ Data quality is high, making the dataset suitable for model training and evaluation without requiring imputation or removal of incomplete records.","metadata":{"id":"-an7cxaaj6l4"}},{"cell_type":"code","source":"# Set plot style\nsns.set(style=\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (10, 6)","metadata":{"id":"MLrUdNj0iPfF","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.992085Z","iopub.status.idle":"2025-08-24T11:45:46.992351Z","shell.execute_reply.started":"2025-08-24T11:45:46.992237Z","shell.execute_reply":"2025-08-24T11:45:46.992249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_columns = ['lesion_id', 'image_id', 'diagnosis']","metadata":{"id":"I8TFXkpZix0u","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.993042Z","iopub.status.idle":"2025-08-24T11:45:46.993338Z","shell.execute_reply.started":"2025-08-24T11:45:46.993184Z","shell.execute_reply":"2025-08-24T11:45:46.993197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for column in categorical_columns:\n    df['diagnosis'].value_counts()\n\ndf['diagnosis'].value_counts()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"JbyriPLUkbe0","outputId":"7b87feb4-b3d6-4c95-c6f8-91b764e8c84b","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.994495Z","iopub.status.idle":"2025-08-24T11:45:46.994837Z","shell.execute_reply.started":"2025-08-24T11:45:46.994679Z","shell.execute_reply":"2025-08-24T11:45:46.994693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nsns.countplot(data=df, x='diagnosis', order=df['diagnosis'].value_counts().index)\nplt.title('Diagnosis Distribution')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":631},"id":"FJV6HrBwkkO-","outputId":"61b2c5a8-497d-4fef-d344-9164cab20fe2","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.995898Z","iopub.status.idle":"2025-08-24T11:45:46.996176Z","shell.execute_reply.started":"2025-08-24T11:45:46.996051Z","shell.execute_reply":"2025-08-24T11:45:46.996065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nsns.countplot(x='split', data=df)\nplt.title(\"Image Count per Data Split (Train/Test/Validation)\")\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"id":"V5M4GM9Sk8ut","outputId":"90f6556e-955f-4a6e-f41d-60b08acdc357","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.997161Z","iopub.status.idle":"2025-08-24T11:45:46.997430Z","shell.execute_reply.started":"2025-08-24T11:45:46.997323Z","shell.execute_reply":"2025-08-24T11:45:46.997334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nsns.countplot(x='fold', data=df)\nplt.title(\"Image Count per Fold\")\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574},"id":"tywUfVnzlaA7","outputId":"3f0cce18-0167-4779-f1ef-8a9bc80f44af","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.998587Z","iopub.status.idle":"2025-08-24T11:45:46.998849Z","shell.execute_reply.started":"2025-08-24T11:45:46.998727Z","shell.execute_reply":"2025-08-24T11:45:46.998740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nsns.countplot(data=df, x='diagnosis', hue='split', order=df['diagnosis'].value_counts().index)\nplt.title(\"Diagnosis Count per Split\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"id":"bfQcncPEle5F","outputId":"6adc3202-bdc1-4e50-f222-a8837d9cc333","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:46.999808Z","iopub.status.idle":"2025-08-24T11:45:47.000139Z","shell.execute_reply.started":"2025-08-24T11:45:46.999969Z","shell.execute_reply":"2025-08-24T11:45:46.999986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nsns.countplot(data=df, x='diagnosis', hue='fold', order=df['diagnosis'].value_counts().index)\nplt.title(\"Diagnosis Count per Fold\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"id":"u5Vakaf5liqb","outputId":"ed8805c2-0503-4705-bad6-26312fa8e403","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.001137Z","iopub.status.idle":"2025-08-24T11:45:47.001332Z","shell.execute_reply.started":"2025-08-24T11:45:47.001238Z","shell.execute_reply":"2025-08-24T11:45:47.001246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lesion_counts = df.groupby(\"diagnosis\")[\"lesion_Id\"].nunique().sort_values(ascending=False)\nprint(\"\\nü¶† Unique Lesion IDs per Diagnosis:\")\nprint(lesion_counts)\n\nlesion_counts.plot(kind='bar', title=\"Unique Lesions per Diagnosis\", ylabel=\"Lesion Count\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":805},"id":"TKTzn9UFlncr","outputId":"100866dd-0378-4e62-e228-934695316044","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.002144Z","iopub.status.idle":"2025-08-24T11:45:47.002449Z","shell.execute_reply.started":"2025-08-24T11:45:47.002294Z","shell.execute_reply":"2025-08-24T11:45:47.002308Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. DATA PREPROCESSING","metadata":{"id":"XZ553PDPlzOI"}},{"cell_type":"markdown","source":"### 3.1 Rename Feature Names","metadata":{"id":"6PtY5Negpvpg"}},{"cell_type":"code","source":"df = df.rename(columns={\n    \"lesion_Id\": 'Lesion_Id',\n    \"image_Id\": 'Image_Id',\n    \"diagnosis\": 'Diagnosis',\n    \"image_Path\": 'Image_Path',\n    \"fold\": 'Fold',\n    \"split\": 'Split'\n})","metadata":{"id":"SH2AOazZlsMC","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.003526Z","iopub.status.idle":"2025-08-24T11:45:47.003881Z","shell.execute_reply.started":"2025-08-24T11:45:47.003692Z","shell.execute_reply":"2025-08-24T11:45:47.003706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2D7KaRzNnVYI","outputId":"fb090b26-85a8-4992-a71e-06275f931097","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.005145Z","iopub.status.idle":"2025-08-24T11:45:47.005401Z","shell.execute_reply.started":"2025-08-24T11:45:47.005289Z","shell.execute_reply":"2025-08-24T11:45:47.005303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace with your image path\nimage_path = '/kaggle/input/mpox-skin-lesion-dataset-version-20-msld-v20/Keywords.jpg'\n\n# Open and display the image\nimage = Image.open(image_path)\nplt.imshow(image)\nplt.axis('off')  # Hide axis\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"sQtM95bfnkKn","outputId":"35b29378-e4f1-4631-e282-4c0518d7150d","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.005941Z","iopub.status.idle":"2025-08-24T11:45:47.006245Z","shell.execute_reply.started":"2025-08-24T11:45:47.006091Z","shell.execute_reply":"2025-08-24T11:45:47.006104Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.2 Map Classes To Disease Code","metadata":{"id":"CZ_YQLyyp3-J"}},{"cell_type":"code","source":"diagnosis_mapping = {\n    'Monkeypox': 'MKP',\n    'Chickenpox': 'CHP',\n    'Measles': 'MSL',\n    'Cowpox' : 'CWP',\n    'Healthy': 'HEALTHY',\n    'HFMD': 'HFMD'\n}\n\ndf['Updated_Diagnosis'] = df['Diagnosis'].map(diagnosis_mapping)","metadata":{"id":"D4dp7osFnbcl","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.007287Z","iopub.status.idle":"2025-08-24T11:45:47.007649Z","shell.execute_reply.started":"2025-08-24T11:45:47.007449Z","shell.execute_reply":"2025-08-24T11:45:47.007465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"BSt5FqtGoPyC","outputId":"dd2185cd-2282-4c49-e0c0-ddd944a8738d","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.008963Z","iopub.status.idle":"2025-08-24T11:45:47.009392Z","shell.execute_reply.started":"2025-08-24T11:45:47.009129Z","shell.execute_reply":"2025-08-24T11:45:47.009145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JY08YDYpDLz","outputId":"2d25d127-9975-4e55-9edb-20fe57eba37c","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.010883Z","iopub.status.idle":"2025-08-24T11:45:47.011215Z","shell.execute_reply.started":"2025-08-24T11:45:47.011055Z","shell.execute_reply":"2025-08-24T11:45:47.011069Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3 Label Encoder","metadata":{"id":"KmdpzY_-qAc6"}},{"cell_type":"code","source":"# Use correct column name\nlabel_encoder = LabelEncoder()\ndf['Updated_Diagnosis_Label'] = label_encoder.fit_transform(df['Diagnosis'])\n# Get mapping from label to encoded value\nlabel_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n# Display result\nprint(\"‚úÖ Label Encoding Mapping:\")\nprint(label_mapping)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvR6PwdCoT2r","outputId":"cefbc137-273e-4b11-a8a6-b6d414130c54","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.013150Z","iopub.status.idle":"2025-08-24T11:45:47.013464Z","shell.execute_reply.started":"2025-08-24T11:45:47.013305Z","shell.execute_reply":"2025-08-24T11:45:47.013321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"X5vNaxp3ojVP","outputId":"1fc832fe-a42a-44c3-b2cd-572e7cead411","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.014744Z","iopub.status.idle":"2025-08-24T11:45:47.015051Z","shell.execute_reply.started":"2025-08-24T11:45:47.014890Z","shell.execute_reply":"2025-08-24T11:45:47.014904Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.4 View Samples of The Diseases Classes","metadata":{"id":"J9i6J15FqFYz"}},{"cell_type":"code","source":"for i in range(len(df)):\n    if not os.path.isfile(df['Image_Path'].iloc[i]):\n        raise FileNotFoundError(f\"Image file not found: {df['Image_Path'].iloc[i]}\")\n\nclass_images = df.drop_duplicates(subset='Diagnosis')\n\ndef plot_class_images(class_images):\n    plt.figure(figsize=(15, 5))\n    num_classes = len(class_images)\n    for i in range(num_classes):\n        plt.subplot(1, num_classes, i + 1)\n        img = plt.imread(class_images['Image_Path'].iloc[i])\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(class_images['Diagnosis'].iloc[i], fontsize=12)\n    plt.tight_layout()\n    plt.show()\nplot_class_images(class_images)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"7nOYkzlkosBE","outputId":"f8cbcb17-49eb-4912-a769-f3d234985390","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.016064Z","iopub.status.idle":"2025-08-24T11:45:47.016373Z","shell.execute_reply.started":"2025-08-24T11:45:47.016213Z","shell.execute_reply":"2025-08-24T11:45:47.016227Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# IMAGE PROCESSING TO ELIMINATE SKIN TONE VARIATION","metadata":{}},{"cell_type":"code","source":"pip install pandas opencv-python tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.017298Z","iopub.status.idle":"2025-08-24T11:45:47.017636Z","shell.execute_reply.started":"2025-08-24T11:45:47.017457Z","shell.execute_reply":"2025-08-24T11:45:47.017470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming df is already defined as a DataFrame\ndf = pd.DataFrame(df)\n\n# Save to CSV in specified folder\ndf.to_csv(r'/kaggle/working/Datasets/output.csv', index=False)\n\nprint(\"CSV saved successfully at C:\\\\Datasets\\\\output.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T11:45:47.018761Z","iopub.status.idle":"2025-08-24T11:45:47.019058Z","shell.execute_reply.started":"2025-08-24T11:45:47.018896Z","shell.execute_reply":"2025-08-24T11:45:47.018912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== SETTINGS ====\ncsv_path = r'/kaggle/working/output.csv'              # Path to your input CSV file\nimage_column = 'Image_Path'                     # Column name for image file paths\nimage_id_column = 'Image_Id'                    # Column name for Image IDs (e.g., MKP_124_02_ORIGINAL)\noutput_dir = r'/kaggle/working/'        # Directory to save augmented images\noutput_csv = r'augmented_images.csv'            # Output CSV to save new augmented paths and IDs\nnum_augments = 180                              # Number of augmentations per image\nnp.random.seed(42)                              # Set seed for reproducibility\n\n# Create output directory if not exists\nos.makedirs(output_dir, exist_ok=True)\n\n# ==== HSV Color Space Augmentation Function ====\ndef hsv_color_space_augmentation(image, num_augments=180):\n    augmented_images = []\n    for i in range(num_augments):\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n        \n        # Shift hue (0 to 179 incrementally)\n        hue_shift = i % 180\n        hsv[..., 0] = (hsv[..., 0] + hue_shift) % 180\n\n        # Slight random variation for Saturation and Value\n        sat_mult = np.random.uniform(0.9, 1.1)\n        val_mult = np.random.uniform(0.9, 1.1)\n        hsv[..., 1] *= sat_mult\n        hsv[..., 2] *= val_mult\n\n        # Clip values and convert back to BGR\n        hsv = np.clip(hsv, 0, 255).astype(np.uint8)\n        aug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\n        augmented_images.append(aug_img)\n    return augmented_images\n\n# ==== LOAD CSV AND FILTER FOR ORIGINAL IMAGES ONLY ====\ndf = pd.read_csv(csv_path)\ndf_original = df[df[image_id_column].str.contains(\"ORIGINAL\", case=False, na=False)]\n\n# ==== AUGMENT IMAGES AND COLLECT DATA ====\naugmented_records = []\n\nfor _, row in df_original.iterrows():\n    img_path = row[image_column]\n    img_id = row[image_id_column]\n\n    if not os.path.isfile(img_path):\n        print(f\"Missing file: {img_path}\")\n        continue\n\n    image = cv2.imread(img_path)\n    if image is None:\n        print(f\"Failed to load: {img_path}\")\n        continue\n\n    aug_images = hsv_color_space_augmentation(image, num_augments=num_augments)\n    base_name = os.path.splitext(os.path.basename(img_path))[0]\n\n    for i, aug_img in enumerate(aug_images):\n        aug_name = f\"{base_name}_hsvaug_{i+1:03d}.jpg\"\n        save_path = os.path.join(output_dir, aug_name)\n        cv2.imwrite(save_path, aug_img)\n\n        # Append data for CSV\n        augmented_records.append({\n            'augmented_image_path': save_path,\n            'original_Image_Id': img_id\n        })\n\n# ==== SAVE NEW CSV FILE ====\naug_df = pd.DataFrame(augmented_records)\naug_df.to_csv(output_csv, index=False)\n\nprint(f\"All ORIGINAL images augmented and saved to {output_dir}\")\nprint(f\"New CSV with augmented image paths saved as {output_csv}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new=pd.read_csv('/kaggle/working/augmented_images.csv')\nnew","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assume df_original is already filtered to contain ORIGINAL images\n# Example: df_original = df[df['Image_Id'].str.contains('ORIGINAL', case=False, na=False)]\n\n# Settings\nnum_augments = 180\noutput_dir = r'/kaggle/working'  # Replace with your actual output directory\n\naugmented_records = []\n\nfor _, row in df_original.iterrows():\n    lesion_id = row['Lesion_Id']\n    original_image_id = row['Image_Id']\n    diagnosis = row['Diagnosis']\n    fold = row['Fold']\n    split = row['Split']\n    base_name = os.path.splitext(os.path.basename(row['Image_Path']))[0]\n\n    for i in range(num_augments):\n        aug_image_id = f\"{original_image_id}_hsvaug_{i+1:03d}\"\n        aug_filename = f\"{base_name}_hsvaug_{i+1:03d}.jpg\"\n        aug_image_path = os.path.join(output_dir, aug_filename)\n\n        augmented_records.append({\n            'lesion_Id': lesion_id,\n            'image_Id': aug_image_id,\n            'diagnosis': diagnosis,\n            'image_Path': aug_image_path,\n            'fold': fold,\n            'split': split\n        })\n\n# Create DataFrame from records\naugmented_df = pd.DataFrame(augmented_records)\n\n# Example: Save to CSV if needed\n# augmented_df.to_csv('augmented_metadata.csv', index=False)\n\nprint(augmented_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augmented_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augmented_df = augmented_df.rename(columns={\n    \"lesion_Id\": 'Lesion_Id',\n    \"image_Id\": 'Image_Id',\n    \"diagnosis\": 'Diagnosis',\n    \"image_Path\": 'Image_Path',\n    \"fold\": 'Fold',\n    \"split\": 'Split'\n})\naugmented_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augmented_df['Diagnosis'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(len(df)):\n    if not os.path.isfile(augmented_df['Image_Path'].iloc[i]):\n        raise FileNotFoundError(f\"Image file not found: {augmented_df['Image_Path'].iloc[i]}\")\n\nclass_images = df.drop_duplicates(subset='Diagnosis')\n\ndef plot_class_images(class_images):\n    plt.figure(figsize=(15, 5))\n    num_classes = len(class_images)\n    for i in range(num_classes):\n        plt.subplot(1, num_classes, i + 1)\n        img = plt.imread(class_images['Image_Path'].iloc[i])\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(class_images['Diagnosis'].iloc[i], fontsize=12)\n    plt.tight_layout()\n    plt.show()\nplot_class_images(class_images)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nsns.countplot(data=augmented_df, x='Diagnosis', order=df['Diagnosis'].value_counts().index)\nplt.title('Diagnosis Distribution')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. AUGMENENT AND BALANCE THE DATASETS","metadata":{"id":"1hDDzg52qgB6"}},{"cell_type":"code","source":"pip install imgaug opencv-python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Load Data ====\ndf = augmented_df  # Your input DataFrame with 'Diagnosis' and 'Image_Path'\n\n# ==== Define Target Range ====\nmin_target = 101340\nmax_target = 180900\n\nbalanced_samples = []\n\nfor label, current_count in df['Diagnosis'].value_counts().items():\n    class_subset = df[df['Diagnosis'] == label]\n\n    if current_count < min_target:\n        # Calculate how many images to augment to reach at least min_target\n        n_to_augment = min_target - current_count\n        print(f\"Augmenting '{label}' from {current_count} to at least {min_target} samples.\")\n\n        # Simple augmentation: randomly sample with replacement\n        augmented_subset = class_subset.sample(n=n_to_augment, replace=True, random_state=42)\n        class_subset = pd.concat([class_subset, augmented_subset]).reset_index(drop=True)\n\n        # Ensure we don't exceed max_target\n        if len(class_subset) > max_target:\n            print(f\"After augmentation, '{label}' exceeds max target. Reducing to {max_target}.\")\n            class_subset = class_subset.sample(n=max_target, random_state=42)\n\n    elif current_count > max_target:\n        # Reduce samples if above max_target\n        print(f\"Reducing '{label}' from {current_count} to {max_target} samples.\")\n        class_subset = class_subset.sample(n=max_target, random_state=42)\n    else:\n        print(f\"'{label}' is within the target range [{min_target}, {max_target}]. Using all {current_count} samples.\")\n\n    balanced_samples.append(class_subset)\n\n# ==== Final Balanced Dataset ====\nbalanced_dataset = pd.concat(balanced_samples).reset_index(drop=True)\n\n# Save to CSV\nbalanced_dataset.to_csv(r'/kaggle/working/Datasets/balanced_dataset.csv', index=False)\nprint(\"Balanced dataset saved at /kaggle/working\\\\Datasets\\\\balanced_dataset.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rename the DataFrame to meta_data\ndf = balanced_dataset\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,4))\nsns.countplot(data=df, x='Diagnosis', order=df['Diagnosis'].value_counts().index)\nplt.title('Diagnosis Distribution')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use correct column name\nlabel_encoder = LabelEncoder()\ndf['Updated_Diagnosis_Label'] = label_encoder.fit_transform(df['Diagnosis'])\n# Get mapping from label to encoded value\nlabel_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n# Display result\nprint(\"‚úÖ Label Encoding Mapping:\")\nprint(label_mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate class weights\nclass_counts = df['Updated_Diagnosis_Label'].value_counts().to_dict()\ntotal_samples = sum(class_counts.values())\nclass_weights = {i: total_samples/count for i, count in enumerate(class_counts.values())}\n\nprint(\"Class weights:\", class_weights)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}